- Multiprocessing, da Threads in Python nie echt parallel laufen
- Implementierung von 2 Layer:
    - Networking/Connection: Ist zuständig für Verbindungsaufbau (sockets), send, recv, Verwaltung der conncections
    - Gossip: Maintain knowlege base, react on messages
- Layer als unterschiedliche Prozesse? 
- IPC via Queues? https://docs.python.org/3/library/multiprocessing.html#pipes-and-queues


Networking: 
- Prozess, der dafür zuständig ist, neue connections anzunehmen
- Prozess, der auf socket empfängt
- Prozess, der neue connections aufbaut und Nachrichten sendet
- Recv + send prozess der selbe? Nein.
  Wir müssen auf incoming messages warten, aber auch verfügbar zum Senden sein: 
  Non-blocking socket + immer switchen zwischen send + recv
  oder: blocking mit timeout
  Zwischen send + recv wechseln ist aber doof, wenn z.B. Peer Nachrichten broadcastet. Dann ist nämlich immer ein recv cycle dabei
  -> send + recv in zwei prozessen handlen
- Pro neue connection neue send+recv prozesse? 
  Schlecht, da sehr viele Prozesse -> #Prozesse >> #CPU-Kerne -> sehr viele Kontext switches -> langsam
  Recv proc kann bei accept generiert werden. Wann send proc? Nur bei init? -> FIxe Anzahl an send procs
  Oder auch nur fixe Anzahl (init am Anfang) an recv proc + epoll auf socketfds. Teile socketfds auf procs auf.
- Wie viele Procs möglich, damit es noch skaliert?


Oder: asyncio:
- server, der die ganze Zeit mit recv beschäftigt ist, und Nachricht an API Layer weitergibt
- Bietet auch methode zum schreiben an. Wir müssen read/write Ende eines Transports sichern

Serialization/Deserialization:
Von Hand; Protobuf ist ganz cool